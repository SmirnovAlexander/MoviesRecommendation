{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation system using movie rating dataset. Film names are taken into account. \n",
    "\n",
    "Top 10 recommendations for user with id $10$ are shown as an example of model usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Investigation\" data-toc-modified-id=\"Investigation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Investigation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Wikipedia:\" data-toc-modified-id=\"Wikipedia:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Wikipedia:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Intro\" data-toc-modified-id=\"Intro-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Intro</a></span></li><li><span><a href=\"#Collaborative-filtering\" data-toc-modified-id=\"Collaborative-filtering-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Collaborative filtering</a></span></li><li><span><a href=\"#Content-based-filtering\" data-toc-modified-id=\"Content-based-filtering-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Content-based filtering</a></span></li><li><span><a href=\"#Hybrid-recommender-systems\" data-toc-modified-id=\"Hybrid-recommender-systems-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Hybrid recommender systems</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Conclusions</a></span></li><li><span><a href=\"#Futher-reading\" data-toc-modified-id=\"Futher-reading-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Futher reading</a></span><ul class=\"toc-item\"><li><span><a href=\"#Paper-1\" data-toc-modified-id=\"Paper-1-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Paper 1</a></span></li><li><span><a href=\"#Summary-on-paper-1\" data-toc-modified-id=\"Summary-on-paper-1-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Summary on paper 1</a></span></li><li><span><a href=\"#Conclusions-on-paper-1\" data-toc-modified-id=\"Conclusions-on-paper-1-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Conclusions on paper 1</a></span></li></ul></li></ul></li><li><span><a href=\"#Solution\" data-toc-modified-id=\"Solution-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Solution</a></span><ul class=\"toc-item\"><li><span><a href=\"#Algorithm-description\" data-toc-modified-id=\"Algorithm-description-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Algorithm description</a></span><ul class=\"toc-item\"><li><span><a href=\"#Argue-of-choice\" data-toc-modified-id=\"Argue-of-choice-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Argue of choice</a></span></li></ul></li><li><span><a href=\"#Working-principles\" data-toc-modified-id=\"Working-principles-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Working principles</a></span></li><li><span><a href=\"#List-of-used-technologies-&amp;-tools\" data-toc-modified-id=\"List-of-used-technologies-&amp;-tools-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>List of used technologies &amp; tools</a></span></li></ul></li><li><span><a href=\"#Success-measurement\" data-toc-modified-id=\"Success-measurement-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Success measurement</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I investigate the field, starting from [Recommender system](https://en.wikipedia.org/wiki/Recommender_system) wikipedia page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia:\n",
    "\n",
    "---\n",
    "### Intro\n",
    "A **recommendation system** is a subclass of information filtering system that seeks to **predict the \"rating\" or \"preference\"** a user would give to an item.\n",
    "\n",
    "Recommender systems usually make use of either or both **collaborative filtering** and **content-based filtering**. \n",
    "\n",
    "**Collaborative filtering** approaches build a **model from a user's past behavior** (items previously purchased or selected and/or numerical ratings given to those items) as well as **similar decisions made by other users**. This model is then used to predict items (or ratings for items) that the user may have an interest in. \n",
    "\n",
    "**Content-based filtering** approaches utilize a series of discrete, pre-tagged characteristics of an item in order to **recommend additional items with similar properties**. \n",
    "\n",
    "Current recommender systems typically **combine** one or more approaches into a **hybrid system**.\n",
    "\n",
    "The **differences** between collaborative and content-based filtering can be demonstrated by comparing two early music recommender systems – Last.fm and Pandora Radio.\n",
    "\n",
    "- Last.fm creates a \"station\" of recommended songs by observing what bands and individual tracks the **user has listened** to on a regular basis and **comparing** those against the **listening behavior of other users**. Last.fm will play tracks that do not appear in the user's library, but are often **played by other users with similar interests**. As this approach leverages the behavior of users, it is an example of a collaborative filtering technique.\n",
    "\n",
    "- Pandora uses the **properties of a song or artist** (a subset of the 400 attributes provided by the Music Genome Project) to seed a \"station\" that **plays music with similar properties**. **User feedback** is used to **refine** the station's results, **deemphasizing** certain **attributes** when a user \"dislikes\" a particular song and **emphasizing** other **attributes** when a user \"likes\" a song. This is an example of a content-based approach.\n",
    "\n",
    "In the above example, Last.fm requires a **large amount of information** about a user to make accurate recommendations. This is an example of the **cold start** problem, and is common in collaborative filtering systems.\n",
    "\n",
    "Whereas Pandora needs **very little information to start**, it is far more limited in scope (for example, it can only make recommendations that are similar to the original seed).\n",
    "\n",
    "### Collaborative filtering\n",
    "\n",
    "Collaborative filtering is based on the assumption that **people who agreed in the past will agree in the future**, and that they **will like similar kinds of items** as they liked in the past. The system generates recommendations using only information about rating profiles for different users or items. By locating peer users/items with a rating history similar to the current user or item, they **generate recommendations** using this **neighborhood**. Collaborative filtering methods are classified as **memory-based** and **model-based**. A well-known example of **memory-based** approaches is the [user-based algorithm](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-98-12.pdf), while that of **model-based** approaches is the [Kernel-Mapping Recommender](https://www.sciencedirect.com/science/article/pii/S0020025512002587).\n",
    "\n",
    "A key **advantage** of the collaborative filtering approach is that it does **not rely on machine analyzable content** and therefore it is capable of **accurately recommending complex items** such as movies **without requiring an \"understanding\"** of the item itself. Many algorithms have been used in **measuring user similarity** or item similarity in recommender systems. For example, the **k-nearest neighbor (k-NN)** approach and the **Pearson Correlation** as first implemented by Allen.\n",
    "\n",
    "When building a model from a user's behavior, a distinction is often made between **explicit** and **implicit** forms of **data collection**.\n",
    "\n",
    "Examples of **explicit** data collection include the following:\n",
    "\n",
    "- Asking a user to **rate an item** on a sliding scale.\n",
    "- Asking a user to **search**.\n",
    "- Asking a user to **rank** a collection of items from favorite to least favorite.\n",
    "- Presenting two items to a user and asking him/her to **choose the better one** of them.\n",
    "- Asking a user to create a **list of items** that he/she **likes** (see Rocchio classification or other similar techniques).\n",
    "\n",
    "Examples of **implicit** data collection include the following:\n",
    "\n",
    "- **Observing** the items that a **user views** in an online store.\n",
    "- Analyzing item/user **viewing times**.\n",
    "- Keeping a record of the items that a **user purchases** online.\n",
    "- Obtaining a list of items that a **user has listened to or watched** on his/her computer.\n",
    "- Analyzing the user's **social network** and **discovering** similar **likes** and **dislikes**.\n",
    "\n",
    "Collaborative filtering approaches often **suffer** from three problems: **cold start**, **scalability**, and **sparsity**.\n",
    "\n",
    "- Cold start: For a **new user** or item, there **isn't enough data** to make accurate recommendations.\n",
    "- Scalability: In many of the environments in which these systems make recommendations, there are **millions of users** and products. Thus, a large amount of **computation power** is often necessary to calculate recommendations.\n",
    "- Sparsity: The **number of items** sold on major e-commerce sites is **extremely large**. The most active users will only have **rated a small subset** of the overall database. Thus, even the most popular items have very few ratings.\n",
    "\n",
    "One of the most famous examples of collaborative filtering is **item-to-item** collaborative filtering (people who buy x also buy y), an algorithm popularized by [Amazon.com's recommender system](https://patentimages.storage.googleapis.com/41/80/fb/07d4d9e61e7431/US6266649.pdf).\n",
    "\n",
    "Collaborative filtering is still **used as part of hybrid systems**.\n",
    "\n",
    "### Content-based filtering\n",
    "\n",
    "Content-based filtering methods are based on a **description of the item** and a profile of the **user's preferences**. These methods are **best suited** to situations where there is **known data on an item** (name, location, description, etc.), but **not on the user**. Content-based recommenders treat recommendation as a **user-specific classification problem** and learn a classifier for the user's likes and dislikes based on an item's features.\n",
    "\n",
    "In this system, **keywords** are used to **describe the items** and a user profile is built to indicate the **type of item this user likes**. In other words, these algorithms try to **recommend items** that are **similar** to those that a **user liked** in the past, or is **examining in the present**. It does not rely on a user sign-in mechanism to generate this often temporary profile. In particular, various **candidate items** are **compared** with **items previously rated by the user** and the **best-matching items** are **recommended**. This approach has its roots in **information retrieval** and **information filtering** research.\n",
    "\n",
    "To create a **user profile**, the system mostly focuses on two **types of information**:\n",
    "\n",
    "1. A model of the **user's preference**.\n",
    "\n",
    "2. A history of the **user's interaction with the recommender system**.\n",
    "\n",
    "Basically, these methods use an **item profile** (i.e., a set of discrete attributes and features) characterizing the item within the system. To **abstract the features** of the items in the system, an **item presentation algorithm** is applied. A widely used algorithm is the **tf–idf representation** (also called vector space representation). The system creates a content-based profile of users based on a **weighted vector of item features**. The **weights denote** the **importance** of **each feature** **to the user** and can be **computed from** individually rated **content vectors** using a variety of techniques. Simple approaches use the **average values of the rated item vector** while other sophisticated methods use **machine learning techniques** such as Bayesian Classifiers, cluster analysis, decision trees, and artificial neural networks in order to **estimate the probability that the user is going to like the item**.\n",
    "\n",
    "A key issue with content-based filtering is whether the system is able to **learn user preferences from users' actions regarding one content source and use them across other content types**. When the system is limited to recommending content of the same type as the user is already using, the value from the recommendation system is significantly less than when other content types from other services can be recommended. For example, recommending news articles based on browsing of news is useful, but would be much more useful when music, videos, products, discussions etc. from different services can be recommended based on news browsing. To overcome this, **most content-based recommender systems** now **use** some form of **hybrid system**.\n",
    "\n",
    "Content-based recommender systems can also include **opinion-based recommender systems**. In some cases, users are allowed to **leave text review or feedback** on the items. These user-generated texts are implicit data for the recommender system because they are **potentially rich resource** of both feature/aspects of the item, and users' evaluation/sentiment to the item. **Features extracted** from the user-generated reviews are **improved meta-data of items**, because as they also **reflect aspects of the item** like meta-data, extracted features are widely concerned by the users. **Sentiments extracted** from the reviews **can be seen as users' rating scores** on the corresponding features. **Popular approaches** of opinion-based recommender system utilize various techniques including text mining, information retrieval, sentiment analysis (see also Multimodal sentiment analysis) and deep learning.\n",
    "\n",
    "### Hybrid recommender systems\n",
    "\n",
    "Most recommender systems now use a **hybrid approach**, combining collaborative filtering, content-based filtering, and other approaches . There is no reason why several different techniques of the same type could not be hybridized. Hybrid approaches can be implemented in several ways: by **making content-based and collaborative-based predictions separately and then combining them**; by **adding content-based capabilities to a collaborative-based approach (and vice versa)**; or by **unifying the approaches into one model** ([complete review of recommender systems](http://pages.stern.nyu.edu/~atuzhili/pdf/TKDE-Paper-as-Printed.pdf)). Several studies that empirically compare the performance of the hybrid with the pure collaborative and content-based methods and demonstrated that the **hybrid methods** can provide **more accurate** recommendations than pure approaches. These methods can also be used to **overcome** some of the common problems in recommender systems such as **cold start** and the **sparsity problem**, as well as the **knowledge engineering bottleneck** in knowledge-based approaches.\n",
    "\n",
    "**Netflix** is a good example of the use of hybrid recommender systems. The website makes recommendations by **comparing the watching and searching habits of similar users** (i.e., collaborative filtering) as well as by **offering movies that share characteristics** with films that a user has rated highly (content-based filtering).\n",
    "\n",
    "Some **hybridization techniques** include:\n",
    "\n",
    "- Weighted: **Combining the score** of different recommendation components numerically.\n",
    "- Switching: **Choosing** among recommendation components and applying the selected one.\n",
    "- Mixed: Recommendations from different recommenders are **presented together** to give the recommendation.\n",
    "- Feature Combination: **Features** derived from different knowledge sources are **combined** together and given to a single recommendation algorithm.\n",
    "- Feature Augmentation: Computing a **feature** or set of features, which is then **part of the input to the next technique**.\n",
    "- Cascade: Recommenders are given strict priority, with the lower priority ones breaking ties in the scoring of the higher ones.\n",
    "- Meta-level: **One recommendation technique** is applied and produces some sort of model, which is then the **input used by the next technique**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two **main approaches** of building a recommendation system:\n",
    "\n",
    "- **Collaborative filtering:** based on matching user preferences with preferences of other users.\n",
    "    - Pluses: do not need to analyze content, recommend without understanding item;\n",
    "    - Problems: cold start, scalability, sparcsity.\n",
    "- **Content-based filtering:** based on matching user preferences with items descriptions (recommend similar items).\n",
    "    - Pluses: need little data about user to start;\n",
    "    - Problems: need understanding of recommended items.\n",
    "\n",
    "Most popular are **hybrid** solutions, which somehow combine these two.\n",
    "\n",
    "It is important to **collect data** about user because it is required in all approaches.\n",
    "There are two types of data collection:\n",
    "- explicit;\n",
    "- implicit.\n",
    "\n",
    "Explicit data collection might partly solve problem of **cold start**. Also this problem may be solved by using **popularity based** recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are doing **movie recommendation** and we should take **movie names** into account, solution will surely contain **content-based filtering**. But as we have **other users data**, **collaborative filtering** takes place.\n",
    "\n",
    "So our goal is to somehow **combine** these two methods in one **hybrid model**.\n",
    "\n",
    "Remarkable note is that **user tags** contains enormous amount of **information** about user preferences, so they surely should be used somehow.\n",
    "\n",
    "My thoughts about **representing user**:\n",
    "- ```number_of_movies```-dimensional **vector with film rating** where exists;\n",
    "- Using bag-of-word or same represent **user tags**, because they give a lot information as discovered from EDA.\n",
    "\n",
    "My thoughts about **representing movie** for content-based filtering:\n",
    "- Make a feature **vector of genre**;\n",
    "- Add **synonyms to genres** (because if we're using tags, common tags are such as \"funny\" are synonyms to genre \"comedy\");\n",
    "- Tokenize **film name** and **add synosyms** to all words to match tags like \"superhero\", \"phsycology\", \"aliens\" and stuff;\n",
    "- Make a **single** bag-of-word **vector** containing presense of all genres, film name and synonyms (that vector might be matched with user's tags vector);\n",
    "- Use information about **year** of film production;\n",
    "- Use information about **actors** (user might prefer one actor to another + match tags such as \"leonardo dicaprio\" and \"will ferrell\");\n",
    "- Use information about **movie creators** (user might prefer one creator to another + match tags such as \"disney\" and \"quentin tarantino\");\n",
    "- Use **tags** that users were giving this film.\n",
    "\n",
    "So right now I am thinking about making **global dictionary** of all listed above and **match** what user have in his vector and film vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futher reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to investigate **state-of-the-art** solutions.\n",
    "\n",
    "First of all I should **find relevant conferences**. What I got:\n",
    "- [KDD](https://www.kdd.org/);\n",
    "- [SIGIR](https://sigir.org/);\n",
    "- [TheWebConf](https://www2020.thewebconf.org/);\n",
    "- [RecSys](https://recsys.acm.org/).\n",
    "\n",
    "On RecSys (conference about recommender systems) I found [best papers](https://recsys.acm.org/best-papers/) tab. There was paper: [Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches](https://arxiv.org/pdf/1907.06902.pdf).\n",
    "\n",
    "This paper is about **top-n recommendation problem** that is being both **coolaborative filtering** and **content-based filtering** problem.\n",
    "\n",
    "I read it and want to give a short **retelling** of this paper.\n",
    "\n",
    "### Paper 1\n",
    "In abstract it is being told that **deep learning techniques flooded** recommender systems field and it is **difficult to keep track** of how they're really doing with recommendation task. They **analyze all modern approaches** and **compare** them to simple known methods.\n",
    "\n",
    "This problem exists because of authors who drop their papers with new methods are **unable to choose right baseline**: some of them are too weak in general, some are not properly fine-tuned. Because of numbers of new paper it is hard to understand what is state-of-the-art now.\n",
    "\n",
    "Goals of authors are to answer questions:\n",
    "- **Reproducibility:** To what extent is recent research in the area reproducible (with reasonable effort?\n",
    "- **Progress:** To what extent are recent algorithms actually leading to better performance results when compared to relatively simple, but well-tuned, baseline methods?\n",
    "\n",
    "Now authors lists number of baselines which will be compared to new algorithms:\n",
    "\n",
    "- **TopPopular:** most popular items to everyone. Popularity is measured by the number of explicit or implicit ratings.\n",
    "\n",
    "- **ItemKNN:** A traditional Collaborative-Filtering (CF) approach based on $k$-nearest-neighborhood (KNN) and item-item similarities. We used the cosine similarity $s_{ij}$ between items $i$ and $j$ computed as $$s_{i j}=\\frac{\\mathbf{r}_{i} \\cdot \\mathbf{r}_{j}}{\\left\\|\\mathbf{r}_{i}\\right\\|\\left\\|\\mathbf{r}_{j}\\right\\|+h}$$ where vectors $r_i, r_j \\in R^{|U|}$ represent the implicit ratings of a user for items $i$ and $j$, respectively, and $|U|$ is the number of users. Ratings can be optionally weighted either with TF-IDF or BM25. Furthermore the similarity may or not be normalized via the product of vector norms. Parameter $h$ (the shrink term) is used to lower the similarity between items having only few interactions. The other parameter of the method is the neighborhood size $k$.\n",
    "\n",
    "- **UserKNN:** A neighborhood-based methodusing collaborative user-user similarities. Hyper-parameters are the same as used for ItemKNN.\n",
    "\n",
    "- **ItemKNN-CBF:** A neighborhood content-based-filtering (CBF) approach with item similarities computed by using item content features (attributes) $$s_{i j}=\\frac{\\mathbf{f}_{i} \\cdot \\mathbf{f}_{j}}{\\left\\|\\mathbf{f}_{i}\\right\\|\\left\\|\\mathbf{f}_{j}\\right\\|+h}$$ where vectors $f_i, f_j \\in R^{|F|}$ describe the features of items $i$ and $j$, respectively, and $|F|$ is the number of features. Features can be optionally weighted either with TF-IDF or BM25. Other parameters are the same used for ItemKNN.\n",
    "\n",
    "- **ItemKNN-CFCBF:** A hybrid CF+CFB algorithm based on item-item similarities. The similarity is computed by first concatenating, for each item $i$, the vector of ratings and the vector of features – $[r_i ,wf_i]$ – and by later computing the cosine similarity between the concatenated vectors. Hyper-parameters are the same used for ItemKNN, plus a parameter $w$ that weights the content features with respect to the ratings.\n",
    "\n",
    "- **$P^3\\alpha$:** A simple graph-based algorithm which implements a random walk between users and items. The method is equivalent to a KNN item-based CF algorithm.\n",
    "\n",
    "- **$RP^3\\beta$:** A version of $P^3\\alpha$ proposed. Here, the outcomes of $P^3\\alpha$ are modified by dividing the similarities by each item’s popularity raised to the power of a coefficient $\\beta$. If $\\beta$ is 0, the algorithm is equivalent to $P^3\\alpha$.\n",
    "\n",
    "They determine **optimal parameters** via **Bayesian search** using the implementation of **Scikit-Optimize**.\n",
    "\n",
    "Afterward goes long part about comparing these baselines to new algorithms.\n",
    "\n",
    "Later goes discussion about **reproducibility** and **hyper-parameter optimization**. It is often a **problem to reproduce a solution** because of low code quality, given by authors, random parameters initialization, private datasets and so on.\n",
    "\n",
    "Their analysis showed that several **recently proposed neural methods** do **not even outperform** conceptually or computationally simpler, sometimes long-known, algorithms. The **level of progress** that is achieved in the field of neural methods is, therefore, **unclear**.\n",
    "\n",
    "One main reason for this **phantom progress** lies in the **choice of the baselines** and the **lack of a proper optimization** of the baselines. In the majority of the investigated cases, not enough information is given about the optimization of the considered baselines. Sometimes, was also found that **mistakes** were made with respect to **data splitting** and the **implementation** of certain evaluation measures and protocols. \n",
    "\n",
    "Also exists problem that the **hunt for better accuracy** values **dominates research activities** in this area, even though it is **not even clear** if slightly **higher accuracy values are relevant** in terms of adding value for recommendation consumers or providers. In fact, a number of research works exist that indicate that **higher accuracy** does **not** necessarily translate into **better** received **recommendations**.  \n",
    "\n",
    "\n",
    "### Summary on paper 1\n",
    "\n",
    "What was very useful for me is a list of baseline methods. For our task might be useful **ItemKNN-CFCBF** because it takes care of both **user ratings** and **film features**.\n",
    "\n",
    "Also was useful that we can determine the **optimal parameters** via **Bayesian search** using the implementation of **Scikit-Optimize**.\n",
    "\n",
    "All **new methods** in the field are **not confirmed to beat** computationally simpler, sometimes long-known, algorithms. The **level of progress** that is achieved in the field of neural methods is, therefore, **unclear**. Main problems are **choice of the baselines** and the **lack of a proper optimization** of the baselines.\n",
    "\n",
    "Also **higher accuracy** does **not** necessarily translate into **better** received **recommendations**.\n",
    "\n",
    "\n",
    "### Conclusions on paper 1\n",
    "\n",
    "I understand that **information** given in this paper may **not** be $100$% **accurate**. I should **repeat all tests** and **compare results**  given in paper. **Another papers** should be read and **another points of views** should be reviewed. But now due to the lack of time we will **assume** that all **what told** in this paper is **correct**.\n",
    "\n",
    "So, having this information we may be sure in chose of classical **ItemKNN-CFCBF** algorithm. What we have to do is to **optimize parameters** and prepare **film features vector**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we finished investigation and we are ready to start.\n",
    "\n",
    "**Problem:** there are $N_u$ users and $N_m$ movies, given a set of training examples (i.e. a set of **triples** (*user*, *movie*, *rating*)), define the **user-movie matrix** $A \\in R^{N_mN_u}$ as:\n",
    "\n",
    "$$A_{m u}=\\left\\{\\begin{array}{ll}R_{m, u}, \\text { User } u \\text { 's rating on Movie } m, & \\text{ if such rating exists}\\\\ ? & \\text { if no such rating }\\end{array}\\right.$$\n",
    "\n",
    "Our task is to **predict all the users’ ratings** on all the movies based on the training set (i.e. existent ratings). In other words, we try to replace all the “question marks” in $A$ by some optimal guesses. In this problem, each rating is a float between $0.5$ and $5$, and the goal is to **minimize the RMSE** (root mean square error) when predicting the ratings on a test set:\n",
    "\n",
    "$$rmse=\\sqrt{\\frac{1}{\\left|S_{\\text {test }}\\right|} \\sum_{(m, u) \\in S_{\\text {test }}}\\left(R_{m, u}-P_{m, u}\\right)^{2}}$$\n",
    "\n",
    "where $(m, u) \\in S_{\\text {test }}$ if User $u$ rates Movie $m$ in the test set, $|S_{\\text {test }}|$ is its cardinality, $R_{m, u}$ is the true rating and $P_{m, u}$ is the prediction based on the recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ItemKNN-CFCBF** \n",
    "\n",
    "The idea is: in order to determine the rating of User $u$ on Movie $m$, we can find other **movies that are similar** to Movie $m$, and based on User $u$’s ratings on those similar movies we infer his rating on Movie $m$. In order to determine which movies are \"similar\", we need to define a **similarity function** (similarity metric).\n",
    "\n",
    "The **similarity** is computed by first concatenating, for each item $i$, the vector of ratings and the vector of features – $[r_i ,wf_i]$ – and by later computing the **cosine similarity** between the concatenated vectors. \n",
    "\n",
    "$$s_{i j}=\\frac{[r_i ,wf_i] \\cdot [r_j ,wf_j]}{\\left\\|[r_i ,wf_i]\\right\\|\\left\\|[r_j ,wf_j]\\right\\|+h}$$\n",
    "\n",
    "Parameter $h$ (the shrink term) is used to lower the similarity between items having only few interactions. Parameter $w$ is weights of content features.\n",
    "\n",
    "**KNN** finds the nearest K neighbors of each movie under the abovedefined similarity function, and use the **weighted means** to predict the rating. The KNN algorithm for movies leads to the following formula:\n",
    "\n",
    "$$P_{m, u}=\\frac{\\sum_{j \\in N_{u}^{K}(m)} s_{m j} R_{j, u}}{\\sum_{j \\in N_{u}^{K}(m)}|s_{m j}|}$$\n",
    "\n",
    "where $N_{u}^{K}(m)=\\{j: j \\text { belongs to the } K \\text { most similar movies to Movie } m \\text { and User } u \\text { has rated } j\\}$, and $s_{m j}$ is the cosine similarity, $R_{j, u}$ are the existent ratings (of User $u$ on Movie $j$) and $P_{m, u}$ is the prediction.\n",
    "\n",
    "To **predict movies** for user, we choose required number of movies which user hadn't seen with highest prediction scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argue of choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we believe to [above paper](https://arxiv.org/pdf/1907.06902.pdf), all **new methods** in the field are **not confirmed to beat** computationally simpler, sometimes long-known, algorithms. The **level of progress** that is achieved in the field of neural methods is, therefore, **unclear**. Main problems are **choice of the baselines** and the **lack of a proper optimization** of the baselines.\n",
    "\n",
    "So we **chose** long known algorithm, that takes care of both **user ratings** and **film features**.\n",
    "\n",
    "We might **make** it **better** **by combining** (e.g. blending predictions) with another algorithms e.g. \"Sparse SVD Algorithm\" or \"Item-Based EM Algorithm\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of used technologies & tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be concerned about **metrics** to check quality of our solution so it will be easy and representative.\n",
    "\n",
    "For example, for [movielens](https://movielens.org/) website metrics might be:\n",
    "- **Success metrics:**\n",
    "    - high rate from user for recommended film;\n",
    "    - number of sharing of recommended film.\n",
    "- **Tracking metrics:**\n",
    "    - daily visitors;\n",
    "    - time spend;\n",
    "    - daily new users;\n",
    "    - average new rates.\n",
    "\n",
    "We might use **A/B testing** for acquiring data.\n",
    "\n",
    "When loading page use new recommendation models for part of website visitors for a while and see how they will act now. Calculate success metrics before and after. Implement new models."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.473px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
